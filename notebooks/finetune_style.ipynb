{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KumYPYVVzhJt"
      },
      "source": [
        "# Fine-tuning a Language Model for Custom-Style Text Generation\n",
        "\n",
        "This notebook demonstrates how to fine-tune a language model to generate text in a custom-style voice. We'll use a dataset of paired emails (standard and custom-style) to teach the model how to transform regular text into custom speech.\n",
        "\n",
        "## Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTBp8A450cnw",
        "outputId": "c8d1766a-26e8-467f-8035-32529f6cc1ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/TheBormann/humanize-LLM.git\n",
        "!cd humanize-LLM && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bc8yICh0c8k",
        "outputId": "4ff3412c-3343-4622-dc45-4231d4981a24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'humanize-LLM' already exists and is not an empty directory.\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.50.0)\n",
            "Requirement already satisfied: datasets>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.5.2)\n",
            "Requirement already satisfied: evaluate>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.4.3)\n",
            "Requirement already satisfied: bitsandbytes>=0.39.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.45.4)\n",
            "Requirement already satisfied: peft>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (0.14.0)\n",
            "Requirement already satisfied: trl>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: wandb>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.19.8)\n",
            "Requirement already satisfied: optimum>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.24.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (0.29.3)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (2.0.2)\n",
            "Requirement already satisfied: tensorboard>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2.18.0)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (4.67.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 18)) (3.10.0)\n",
            "Requirement already satisfied: seaborn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (0.13.2)\n",
            "Requirement already satisfied: pytest>=7.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (8.3.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2024.12.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29.0->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29.0->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29.0->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29.0->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29.0->-r requirements.txt (line 2)) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29.0->-r requirements.txt (line 2)) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 3)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 3)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 3)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 3)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.10.0->-r requirements.txt (line 3)) (3.11.14)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.20.3->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl>=0.2.2->-r requirements.txt (line 8)) (13.9.4)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (5.29.4)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (2.24.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.15.0->-r requirements.txt (line 9)) (75.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 14)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 14)) (1.71.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 14)) (3.7)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 14)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 14)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=2.13.0->-r requirements.txt (line 14)) (3.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 16)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 16)) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 16)) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 17)) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 17)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 17)) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 18)) (3.2.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 20)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=7.4.0->-r requirements.txt (line 20)) (1.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 3)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 3)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 3)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 3)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 3)) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.10.0->-r requirements.txt (line 3)) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 9)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.15.0->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.15.0->-r requirements.txt (line 9)) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.29.0->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.29.0->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.29.0->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers>=4.29.0->-r requirements.txt (line 2)) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.13.0->-r requirements.txt (line 14)) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.2.2->-r requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl>=0.2.2->-r requirements.txt (line 8)) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements.txt (line 9)) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl>=0.2.2->-r requirements.txt (line 8)) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iF8_x5vMzhJz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import sys\n",
        "import pandas as pd\n",
        "from typing import List, Dict\n",
        "\n",
        "# Add the parent directory to the path\n",
        "sys.path.append('/content/humanize-LLM')\n",
        "\n",
        "from src.utils.model_utils import get_local_model\n",
        "from src.models.base import FinetuningArguments, PEFTArguments\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    stream=sys.stdout\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lox5td4izhJ0"
      },
      "source": [
        "## Data Loading and Preparation\n",
        "\n",
        "We'll load our dataset of paired emails from a CSV file. The dataset contains regular emails in the `body_ai` column and their custom-style versions in the `body` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "c__CwiEmzhJ0"
      },
      "outputs": [],
      "source": [
        "def load_emails_from_csv(file_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load emails from a CSV file with semicolon delimiter.\"\"\"\n",
        "    df = pd.read_csv(file_path, sep=';')\n",
        "    logger.info(f\"Loaded {len(df)} emails from {file_path}\")\n",
        "    return df\n",
        "\n",
        "def prepare_training_data(emails_df: pd.DataFrame) -> List[Dict[str, str]]:\n",
        "    \"\"\"Prepare training data from emails dataframe.\n",
        "\n",
        "    Creates direct style transfer pairs where:\n",
        "    - prompt: [AI-generated email from body_ai]\n",
        "    - response: [Your styled version from body]\n",
        "    \"\"\"\n",
        "    training_data = []\n",
        "\n",
        "    for _, row in emails_df.iterrows():\n",
        "        if pd.isna(row['body']) or pd.isna(row['body_ai']):\n",
        "            continue\n",
        "\n",
        "        sample = {\n",
        "            \"prompt\": row['body_ai'],  # Direct AI-generated email\n",
        "            \"response\": row['body']     # Your styled version\n",
        "        }\n",
        "\n",
        "        training_data.append(sample)\n",
        "\n",
        "    logger.info(f\"Created {len(training_data)} direct style transfer pairs\")\n",
        "    return training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDVh-N2kzhJ1",
        "outputId": "108ec701-a1f2-4811-dc25-bc0790beb0ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample training pair:\n",
            "Prompt (AI-generated): Hi [Name],\\n\\nI'm [Your Name], founder of [Startup Name]. We're revolutionizing [industry] through [key innovation]. Would you have time next week to ...\n",
            "Response (custom-style): Ahoy [Name],\\n\\nYer lookin' at [Your Name], fearsome captain of [Startup Name]. We be chartin' treacherous waters of [industry] with [key innovation] ...\n",
            "Total training pairs: 69\n"
          ]
        }
      ],
      "source": [
        "# Set the path to the CSV file\n",
        "EMAIL_CSV_PATH = '/content/humanize-LLM/data/manual_emails.csv'\n",
        "\n",
        "# Load and prepare the dataset\n",
        "emails_df = load_emails_from_csv(EMAIL_CSV_PATH)\n",
        "training_data = prepare_training_data(emails_df)\n",
        "\n",
        "# Display a sample of the training data\n",
        "if training_data:\n",
        "    print(\"Sample training pair:\")\n",
        "    print(f\"Prompt (AI-generated): {training_data[0]['prompt'][:150]}...\")\n",
        "    print(f\"Response (custom-style): {training_data[0]['response'][:150]}...\")\n",
        "    print(f\"Total training pairs: {len(training_data)}\")\n",
        "else:\n",
        "    print(\"No training data found or prepared.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7XNF6y0zhJ1"
      },
      "source": [
        "## Fine-tuning Function\n",
        "\n",
        "Now we'll define a function to fine-tune our model using the prepared dataset. We'll use Parameter-Efficient Fine-Tuning (PEFT) with LoRA to efficiently adapt the model to our custom-style text generation task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wAQjx1gqzhJ1"
      },
      "outputs": [],
      "source": [
        "def finetune_model(model_name: str, dataset: List[Dict[str, str]],\n",
        "                  output_dir: str, use_lora: bool = True):\n",
        "    \"\"\"Fine-tune model on custom-style email dataset.\"\"\"\n",
        "    # Load base model\n",
        "    model = get_local_model(model_name)\n",
        "\n",
        "    # Load the model\n",
        "    model.load_model(model_name)\n",
        "\n",
        "    # Configure fine-tuning arguments\n",
        "    ft_args = FinetuningArguments(\n",
        "        train_data=dataset,\n",
        "        epochs=3,  # Usually 2-5 epochs works well for style tuning\n",
        "        batch_size=1,  # Small batch size for memory efficiency\n",
        "        learning_rate=2e-5  # Lower learning rate to preserve general knowledge\n",
        "    )\n",
        "\n",
        "    # Configure LoRA if used\n",
        "    peft_args = None\n",
        "    if use_lora:\n",
        "        peft_args = PEFTArguments(\n",
        "            method=\"lora\",\n",
        "            rank=16,  # Higher rank for more expressiveness\n",
        "            alpha=32,\n",
        "            dropout=0.05\n",
        "        )\n",
        "\n",
        "    # Run fine-tuning\n",
        "    result = model.finetune(ft_args, output_dir=output_dir, peft_args=peft_args)\n",
        "    logger.info(f\"Fine-tuning result: {result}\")\n",
        "\n",
        "    # Test the model with direct input\n",
        "    test_prompt = \"Dear Team,\\n\\nI wanted to remind everyone about our quarterly meeting next Tuesday at 2pm. Please bring your project updates and be prepared to discuss next steps.\\n\\nRegards,\\nManager\"\n",
        "    response = model.generate(test_prompt, max_new_tokens=300)\n",
        "\n",
        "    logger.info(f\"Sample output after fine-tuning:\\n{response}\")\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzomE3qazhJ2"
      },
      "source": [
        "## Run the Fine-tuning Process\n",
        "\n",
        "Now let's set up our configuration and run the fine-tuning process. We'll use a small model like Ministral-3b-instruct for faster fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "a804f29419b14e49872288ffb5bcb6c8",
            "4867e2aecc1048c6b195e07ed1965a31",
            "0c51211149b84dd3ab13c5dc56b1b9d9",
            "6ae57f3754e24e519d40870f174644cf",
            "124b2bc92d084cfeaea69ca599d38b3b",
            "1a69a2014b75456fb6907a979e3a4c75",
            "2953e34a1cef442f9caca67a1e121fde",
            "339a68b5941e4f34bb9da94b59bfc2b4",
            "030fcc792cc24b6db93fca975fc76b6d",
            "fc789e53a29d4ceebf1375170a3c280a",
            "43a33b08d6b64f11966d30cb73e8a415"
          ]
        },
        "id": "zBq3FWyXzhJ2",
        "outputId": "afa3efab-4b32-429b-9cba-9e1cda165c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a804f29419b14e49872288ffb5bcb6c8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Configuration\n",
        "MODEL_NAME = \"ministral/Ministral-3b-instruct\"  # For fine-tuning\n",
        "OUTPUT_DIR = \"../output/custom_style_model\"\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Fine-tune the model\n",
        "# Note: This may take a while depending on your hardware\n",
        "model = finetune_model(MODEL_NAME, training_data, OUTPUT_DIR, use_lora=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLIfAqFtzhJ2"
      },
      "source": [
        "## Test the Fine-tuned Model\n",
        "\n",
        "Let's test our fine-tuned model with some example prompts to see how well it generates custom-style text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQjAlOrGzhJ2"
      },
      "outputs": [],
      "source": [
        "# Test with different prompts\n",
        "test_prompts = [\n",
        "    \"Hello, I'm writing to inquire about your services. Could we schedule a call next week?\",\n",
        "    \"Dear HR, I'm submitting my application for the software developer position. I have 5 years of experience.\",\n",
        "    \"Team, please remember to submit your reports by Friday. The client is expecting our analysis.\",\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(test_prompts):\n",
        "    print(f\"\\nTest Prompt {i+1}:\\n{prompt}\")\n",
        "    response = model.generate(prompt, max_new_tokens=300)\n",
        "    print(f\"\\ncustom-Style Response:\\n{response}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-htzHMjzhJ2"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've demonstrated how to fine-tune a language model to generate text in a specific style - in this case, custom-speak. The same approach can be used for other stylistic transformations, such as formal to casual, technical to simple, or any other style you have paired examples for.\n",
        "\n",
        "Key points:\n",
        "\n",
        "1. We used direct style transfer pairs (standard → custom) for training\n",
        "2. We applied LoRA for parameter-efficient fine-tuning\n",
        "3. We kept the learning rate low to preserve the model's general knowledge\n",
        "4. We tested the model with various prompts to evaluate its style adaptation\n",
        "\n",
        "This approach can be extended to personalize AI responses to match your unique voice or brand tone."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a804f29419b14e49872288ffb5bcb6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4867e2aecc1048c6b195e07ed1965a31",
              "IPY_MODEL_0c51211149b84dd3ab13c5dc56b1b9d9",
              "IPY_MODEL_6ae57f3754e24e519d40870f174644cf"
            ],
            "layout": "IPY_MODEL_124b2bc92d084cfeaea69ca599d38b3b"
          }
        },
        "4867e2aecc1048c6b195e07ed1965a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a69a2014b75456fb6907a979e3a4c75",
            "placeholder": "​",
            "style": "IPY_MODEL_2953e34a1cef442f9caca67a1e121fde",
            "value": "Loading checkpoint shards:  33%"
          }
        },
        "0c51211149b84dd3ab13c5dc56b1b9d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_339a68b5941e4f34bb9da94b59bfc2b4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_030fcc792cc24b6db93fca975fc76b6d",
            "value": 1
          }
        },
        "6ae57f3754e24e519d40870f174644cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc789e53a29d4ceebf1375170a3c280a",
            "placeholder": "​",
            "style": "IPY_MODEL_43a33b08d6b64f11966d30cb73e8a415",
            "value": " 1/3 [00:20&lt;00:41, 20.99s/it]"
          }
        },
        "124b2bc92d084cfeaea69ca599d38b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a69a2014b75456fb6907a979e3a4c75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2953e34a1cef442f9caca67a1e121fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "339a68b5941e4f34bb9da94b59bfc2b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "030fcc792cc24b6db93fca975fc76b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc789e53a29d4ceebf1375170a3c280a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43a33b08d6b64f11966d30cb73e8a415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}